# Integracja z lokalnym agentem sterujÄ…cym

## ğŸ¤– PrzeglÄ…d rozwiÄ…zaÅ„

JeÅ›li chcesz sterowaÄ‡ GPT-Pilot poprzez wÅ‚asnego lokalnego agenta zamiast VS Code, masz kilka opcji wykorzystujÄ…cych istniejÄ…ce mechanizmy.

## ğŸ”§ RozwiÄ…zanie 1: Rozszerzenie IPC Client (Zalecane)

### Wykorzystanie istniejÄ…cego protokoÅ‚u IPC

MoÅ¼esz stworzyÄ‡ wÅ‚asnego agenta, ktÃ³ry bÄ™dzie dziaÅ‚aÅ‚ jako "mock VS Code extension":

```python
# custom_agent_server.py
import asyncio
import json
from typing import Dict, Any, Optional

class LocalAgentServer:
    """
    Lokalny agent sterujÄ…cy GPT-Pilot przez protokÃ³Å‚ IPC
    """
    
    def __init__(self, host="localhost", port=8125):
        self.host = host
        self.port = port
        self.server = None
        self.writer = None
        self.message_handlers = {}
        self.conversation_state = {}
        
    def add_handler(self, message_type: str, handler):
        """Dodaj handler dla konkretnego typu wiadomoÅ›ci"""
        self.message_handlers[message_type] = handler
        
    async def handle_connection(self, reader, writer):
        """ObsÅ‚uga poÅ‚Ä…czenia z GPT-Pilot"""
        self.writer = writer
        print("ğŸ”— GPT-Pilot connected")
        
        try:
            while True:
                # Odczytaj dÅ‚ugoÅ›Ä‡ wiadomoÅ›ci (4 bajty)
                length_data = await reader.read(4)
                if not length_data:
                    break
                    
                message_length = int.from_bytes(length_data, byteorder="big")
                
                # Odczytaj wiadomoÅ›Ä‡ JSON
                message_data = await reader.read(message_length)
                message = json.loads(message_data.decode("utf-8"))
                
                print(f"ğŸ“¨ Received: {message['type']}")
                
                # PrzetwÃ³rz wiadomoÅ›Ä‡
                await self.process_message(message)
                
        except Exception as e:
            print(f"âŒ Connection error: {e}")
        finally:
            writer.close()
            await writer.wait_closed()
            print("ğŸ”Œ GPT-Pilot disconnected")
    
    async def process_message(self, message: Dict[str, Any]):
        """PrzetwÃ³rz otrzymanÄ… wiadomoÅ›Ä‡"""
        msg_type = message.get("type")
        
        if msg_type in self.message_handlers:
            response = await self.message_handlers[msg_type](message)
            if response:
                await self.send_response(response)
        else:
            # DomyÅ›lna obsÅ‚uga
            await self.default_handler(message)
    
    async def send_response(self, response: str):
        """WyÅ›lij odpowiedÅº do GPT-Pilot"""
        if self.writer:
            response_json = json.dumps({
                "type": "response",
                "content": response
            })
            response_bytes = response_json.encode("utf-8")
            self.writer.write(response_bytes)
            await self.writer.drain()
    
    async def default_handler(self, message: Dict[str, Any]):
        """DomyÅ›lna obsÅ‚uga wiadomoÅ›ci"""
        msg_type = message.get("type")
        content = message.get("content", "")
        
        if msg_type == "user_input_request":
            # GPT-Pilot pyta o coÅ›
            question = content
            print(f"â“ Question: {question}")
            
            # Tutaj TwÃ³j agent moÅ¼e:
            # 1. AnalizowaÄ‡ pytanie
            # 2. SprawdziÄ‡ stan konwersacji
            # 3. PodjÄ…Ä‡ autonomicznÄ… decyzjÄ™
            # 4. Lub zapytaÄ‡ zewnÄ™trzny system
            
            response = await self.ai_decision_maker(question, message)
            await self.send_response(response)
            
        elif msg_type == "stream":
            # GPT-Pilot streamuje tekst
            print(f"ğŸ’¬ Stream: {content}", end="")
            
        elif msg_type == "verbose":
            # ZwykÅ‚a wiadomoÅ›Ä‡
            category = message.get("category", "system")
            print(f"ğŸ“¢ [{category}] {content}")
            
        elif msg_type == "progress":
            # Informacja o postÄ™pie
            task_info = content.get("task", {})
            print(f"â³ Progress: {task_info.get('description', 'Unknown task')}")
    
    async def ai_decision_maker(self, question: str, context: Dict[str, Any]) -> str:
        """
        TwÃ³j AI agent podejmuje decyzje
        """
        # PrzykÅ‚ad prostej logiki decyzyjnej
        question_lower = question.lower()
        
        # Analiza kontekstu
        category = context.get("category", "")
        
        if "project name" in question_lower:
            return "MyAwesomeApp"
            
        elif "continue" in question_lower or "proceed" in question_lower:
            return "yes"
            
        elif "technology" in question_lower or "template" in question_lower:
            return "vite_react"  # Wybierz szablon
            
        elif "description" in question_lower:
            return "A modern web application built with React and TypeScript"
            
        # Dla bardziej zÅ‚oÅ¼onych pytaÅ„ - integracja z LLM
        elif "agent:architect" in category:
            return await self.consult_llm_for_architecture(question)
            
        elif "agent:developer" in category:
            return await self.consult_llm_for_development(question)
        
        # DomyÅ›lna odpowiedÅº
        return "continue"
    
    async def consult_llm_for_architecture(self, question: str) -> str:
        """Skonsultuj siÄ™ z LLM dla pytaÅ„ architektonicznych"""
        # Tutaj moÅ¼esz zintegrowaÄ‡ z OpenAI, Anthropic, etc.
        # PrzykÅ‚ad:
        """
        import openai
        
        response = await openai.ChatCompletion.acreate(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an expert software architect."},
                {"role": "user", "content": f"GPT-Pilot asks: {question}. Provide a brief, practical answer."}
            ]
        )
        return response.choices[0].message.content
        """
        return "continue"  # Placeholder
    
    async def consult_llm_for_development(self, question: str) -> str:
        """Skonsultuj siÄ™ z LLM dla pytaÅ„ deweloperskich"""
        # Podobnie jak wyÅ¼ej, ale z kontekstem deweloperskim
        return "continue"  # Placeholder
    
    async def start(self):
        """Uruchom serwer agenta"""
        print(f"ğŸš€ Starting Local Agent Server on {self.host}:{self.port}")
        self.server = await asyncio.start_server(
            self.handle_connection,
            self.host,
            self.port
        )
        
        print(f"âœ… Agent ready! GPT-Pilot can now connect to {self.host}:{self.port}")
        async with self.server:
            await self.server.serve_forever()

# PrzykÅ‚ad uÅ¼ycia
async def main():
    agent = LocalAgentServer()
    
    # Dodaj wÅ‚asne handlery
    async def custom_progress_handler(message):
        print(f"ğŸ¯ Custom progress handler: {message}")
        return None
    
    agent.add_handler("progress", custom_progress_handler)
    
    # Uruchom serwer
    await agent.start()

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ”§ RozwiÄ…zanie 2: Nowy adapter UI

Alternatywnie, moÅ¼esz stworzyÄ‡ nowy adapter UI bezpoÅ›rednio w GPT-Pilot:

```python
# core/ui/agent_ui.py
from typing import Optional
import asyncio
import json
from core.ui.base import UIBase, UISource, UserInput
from core.log import get_logger

log = get_logger(__name__)

class LocalAgentUI(UIBase):
    """
    UI adapter dla lokalnego agenta sterujÄ…cego
    """
    
    def __init__(self, agent_endpoint: str = "http://localhost:9000"):
        self.agent_endpoint = agent_endpoint
        self.session = None
        
    async def start(self) -> bool:
        """PoÅ‚Ä…cz z lokalnym agentem"""
        try:
            # Tutaj moÅ¼esz uÅ¼yÄ‡ HTTP, WebSocket, lub innego protokoÅ‚u
            import aiohttp
            self.session = aiohttp.ClientSession()
            
            # Test connection
            async with self.session.get(f"{self.agent_endpoint}/health") as resp:
                if resp.status == 200:
                    log.info("Connected to local agent")
                    return True
                    
        except Exception as e:
            log.error(f"Failed to connect to local agent: {e}")
            return False
    
    async def stop(self):
        """RozÅ‚Ä…cz z agentem"""
        if self.session:
            await self.session.close()
    
    async def ask_question(
        self,
        question: str,
        *,
        buttons: Optional[dict[str, str]] = None,
        **kwargs
    ) -> UserInput:
        """Zadaj pytanie lokalnemu agentowi"""
        
        payload = {
            "type": "question",
            "question": question,
            "buttons": buttons,
            "context": kwargs
        }
        
        try:
            async with self.session.post(
                f"{self.agent_endpoint}/decide",
                json=payload
            ) as resp:
                result = await resp.json()
                
                if result.get("button"):
                    return UserInput(button=result["button"])
                else:
                    return UserInput(text=result.get("text", ""))
                    
        except Exception as e:
            log.error(f"Agent decision failed: {e}")
            # Fallback - zwrÃ³Ä‡ domyÅ›lnÄ… odpowiedÅº
            if buttons:
                return UserInput(button=list(buttons.keys())[0])
            return UserInput(text="continue")
    
    async def send_message(
        self,
        message: str,
        *,
        source: Optional[UISource] = None,
        **kwargs
    ):
        """WyÅ›lij wiadomoÅ›Ä‡ do agenta (dla obserwacji)"""
        payload = {
            "type": "message",
            "content": message,
            "source": source.type_name if source else None,
            "context": kwargs
        }
        
        try:
            async with self.session.post(
                f"{self.agent_endpoint}/observe",
                json=payload
            ) as resp:
                pass  # Agent moÅ¼e logowaÄ‡ lub analizowaÄ‡
        except Exception as e:
            log.debug(f"Failed to send observation to agent: {e}")
    
    # Implementuj pozostaÅ‚e metody...
    async def send_stream_chunk(self, chunk: Optional[str], **kwargs):
        # MoÅ¼esz streamowaÄ‡ do agenta lub ignorowaÄ‡
        pass
```

## ğŸ”§ RozwiÄ…zanie 3: WebSocket Agent

Dla bardziej zaawansowanej komunikacji dwukierunkowej:

```python
# websocket_agent.py
import asyncio
import websockets
import json
from typing import Dict, Any

class WebSocketAgent:
    """
    Agent komunikujÄ…cy siÄ™ przez WebSocket
    """
    
    def __init__(self, port=9001):
        self.port = port
        self.clients = set()
        self.conversation_state = {}
        
    async def register_client(self, websocket, path):
        """Zarejestruj nowego klienta (GPT-Pilot)"""
        self.clients.add(websocket)
        print(f"ğŸ”— Client connected: {websocket.remote_address}")
        
        try:
            async for message in websocket:
                data = json.loads(message)
                response = await self.handle_message(data)
                
                if response:
                    await websocket.send(json.dumps(response))
                    
        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            self.clients.remove(websocket)
            print(f"ğŸ”Œ Client disconnected")
    
    async def handle_message(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ObsÅ‚uÅ¼ wiadomoÅ›Ä‡ od GPT-Pilot"""
        msg_type = data.get("type")
        
        if msg_type == "question":
            # Autonomiczna decyzja
            question = data.get("question", "")
            decision = await self.make_decision(question, data)
            
            return {
                "type": "answer",
                "content": decision
            }
            
        elif msg_type == "status":
            # Aktualizacja statusu
            await self.update_status(data)
            
        return None
    
    async def make_decision(self, question: str, context: Dict[str, Any]) -> str:
        """Podejmij autonomicznÄ… decyzjÄ™"""
        # Twoja logika AI/ML
        # MoÅ¼esz tutaj:
        # 1. AnalizowaÄ‡ historiÄ™ konwersacji
        # 2. UÅ¼ywaÄ‡ reguÅ‚ biznesowych
        # 3. KonsultowaÄ‡ z zewnÄ™trznym LLM
        # 4. UÅ¼ywaÄ‡ modeli ML do predykcji
        
        return "continue"  # Placeholder
    
    async def start_server(self):
        """Uruchom serwer WebSocket"""
        print(f"ğŸš€ WebSocket Agent starting on port {self.port}")
        
        start_server = websockets.serve(
            self.register_client,
            "localhost",
            self.port
        )
        
        await start_server
        print(f"âœ… WebSocket Agent ready on ws://localhost:{self.port}")
        
        # Utrzymuj serwer
        await asyncio.Future()  # Run forever

# Uruchomienie
if __name__ == "__main__":
    agent = WebSocketAgent()
    asyncio.run(agent.start_server())
```

## ğŸš€ Integracja z GPT-Pilot

### Konfiguracja dla IPC Agent:

```json
{
  "ui": {
    "type": "ipc",
    "host": "localhost",
    "port": 8125
  }
}
```

### Konfiguracja dla HTTP Agent:

```json
{
  "ui": {
    "type": "agent",
    "endpoint": "http://localhost:9000"
  }
}
```

## ğŸ§  Zaawansowane moÅ¼liwoÅ›ci agenta

### 1. Analiza kontekstu
```python
class ContextAnalyzer:
    def __init__(self):
        self.conversation_history = []
        self.project_state = {}
    
    def analyze_question(self, question: str, context: dict) -> str:
        """Analizuj pytanie w kontekÅ›cie caÅ‚ej konwersacji"""
        
        # Dodaj do historii
        self.conversation_history.append({
            "question": question,
            "context": context,
            "timestamp": time.time()
        })
        
        # Analiza wzorcÃ³w
        if self.is_repetitive_question(question):
            return self.get_cached_response(question)
            
        # Analiza fazy projektu
        if context.get("category") == "agent:architect":
            return self.architectural_decision(question)
            
        return "continue"
```

### 2. Integracja z LLM
```python
async def llm_consultation(self, question: str, context: dict) -> str:
    """Skonsultuj decyzjÄ™ z zewnÄ™trznym LLM"""
    
    system_prompt = f"""
    JesteÅ› agentem sterujÄ…cym GPT-Pilot. 
    Projekt: {context.get('project_name', 'Unknown')}
    Faza: {context.get('category', 'Unknown')}
    
    Odpowiedz krÃ³tko i konkretnie na pytanie GPT-Pilot.
    """
    
    # UÅ¼yj swojego ulubionego LLM API
    response = await your_llm_client.chat(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ]
    )
    
    return response.content
```

## ğŸ¯ Zalecenia

1. **Zacznij od RozwiÄ…zania 1** - wykorzystaj gotowy protokÃ³Å‚ IPC
2. **Dodaj logikÄ™ decyzyjnÄ…** - reguÅ‚y biznesowe + LLM consultation
3. **Monitoruj stan** - Å›ledÅº postÄ™p i podejmuj inteligentne decyzje
4. **Testuj stopniowo** - zacznij od prostych odpowiedzi, rozbudowuj

## ğŸ”§ PrzykÅ‚ad uruchomienia

```bash
# Terminal 1: Uruchom agenta
python custom_agent_server.py

# Terminal 2: Uruchom GPT-Pilot z konfiguracjÄ… IPC
python main.py --config config-with-ipc.json
```

Ten sposÃ³b pozwala na peÅ‚nÄ… kontrolÄ™ nad GPT-Pilot przez Twojego lokalnego agenta, wykorzystujÄ…c istniejÄ…ce, przetestowane mechanizmy komunikacji.