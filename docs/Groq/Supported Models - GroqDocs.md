---
created: 2025-06-29T04:26:11
source: https://console.groq.com/docs/models
---

# Supported Models - GroqDocs

> Documentation for Groq products and APIs.

---
[Supported Models](https://console.groq.com/docs/models#supported-models)
-------------------------------------------------------------------------

GroqCloud currently supports the following models:

  

### [Production Models](https://console.groq.com/docs/models#production-models)

**Note:** Production models are intended for use in your production environments. They meet or exceed our high standards for speed, quality, and reliability. Read more [here](https://console.groq.com/docs/deprecations).

| MODEL ID | DEVELOPER | CONTEXT WINDOW (TOKENS) | MAX COMPLETION TOKENS | MAX FILE SIZE | DETAILS |
| --- | --- | --- | --- | --- | --- |
| 
distil-whisper-large-v3-en



 | 

Hugging Face



 | 

\-



 | 

\-



 | 

100 MB



 | 

[Details](https://console.groq.com/docs/model/distil-whisper-large-v3-en)



 |
| 

gemma2-9b-it



 | 

Google



 | 

8,192



 | 

8,192



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/gemma2-9b-it)



 |
| 

llama-3.1-8b-instant



 | 

Meta



 | 

131,072



 | 

131,072



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/llama-3.1-8b-instant)



 |
| 

llama-3.3-70b-versatile



 | 

Meta



 | 

131,072



 | 

32,768



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/llama-3.3-70b-versatile)



 |
| 

meta-llama/llama-guard-4-12b



 | 

Meta



 | 

131,072



 | 

1,024



 | 

20 MB



 | 

[Details](https://console.groq.com/docs/model/meta-llama/llama-guard-4-12b)



 |
| 

whisper-large-v3



 | 

OpenAI



 | 

\-



 | 

\-



 | 

100 MB



 | 

[Details](https://console.groq.com/docs/model/whisper-large-v3)



 |
| 

whisper-large-v3-turbo



 | 

OpenAI



 | 

\-



 | 

\-



 | 

100 MB



 | 

[Details](https://console.groq.com/docs/model/whisper-large-v3-turbo)



 |

  

### [Preview Models](https://console.groq.com/docs/models#preview-models)

**Note:** Preview models are intended for evaluation purposes only and should not be used in production environments as they may be discontinued at short notice. Read more about deprecations [here](https://console.groq.com/docs/deprecations).

| MODEL ID | DEVELOPER | CONTEXT WINDOW (TOKENS) | MAX COMPLETION TOKENS | MAX FILE SIZE | DETAILS |
| --- | --- | --- | --- | --- | --- |
| 
deepseek-r1-distill-llama-70b



 | 

DeepSeek / Meta



 | 

131,072



 | 

131,072



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/deepseek-r1-distill-llama-70b)



 |
| 

meta-llama/llama-4-maverick-17b-128e-instruct



 | 

Meta



 | 

131,072



 | 

8,192



 | 

20 MB



 | 

[Details](https://console.groq.com/docs/model/meta-llama/llama-4-maverick-17b-128e-instruct)



 |
| 

meta-llama/llama-4-scout-17b-16e-instruct



 | 

Meta



 | 

131,072



 | 

8,192



 | 

20 MB



 | 

[Details](https://console.groq.com/docs/model/meta-llama/llama-4-scout-17b-16e-instruct)



 |
| 

meta-llama/llama-prompt-guard-2-22m



 | 

Meta



 | 

512



 | 

512



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/meta-llama/llama-prompt-guard-2-22m)



 |
| 

meta-llama/llama-prompt-guard-2-86m



 | 

Meta



 | 

512



 | 

512



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/meta-llama/llama-prompt-guard-2-86m)



 |
| 

mistral-saba-24b



 | 

Mistral AI



 | 

32,768



 | 

32,768



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/mistral-saba-24b)



 |
| 

playai-tts



 | 

PlayAI



 | 

8,192



 | 

8,192



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/playai-tts)



 |
| 

playai-tts-arabic



 | 

PlayAI



 | 

8,192



 | 

8,192



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/playai-tts-arabic)



 |
| 

qwen-qwq-32b



 | 

Alibaba Cloud



 | 

131,072



 | 

131,072



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/qwen-qwq-32b)



 |
| 

qwen/qwen3-32b



 | 

Alibaba Cloud



 | 

131,072



 | 

40,960



 | 

\-



 | 

[Details](https://console.groq.com/docs/model/qwen/qwen3-32b)



 |

  

### [Preview Systems](https://console.groq.com/docs/models#preview-systems)

Systems are a collection of models and tools that work together to answer a user query.

**Note:** Preview systems are intended for evaluation purposes only and should not be used in production environments as they may be discontinued at short notice. Read more about deprecations [here](https://console.groq.com/docs/deprecations).

| MODEL ID | DEVELOPER | CONTEXT WINDOW (TOKENS) | MAX COMPLETION TOKENS | MAX FILE SIZE | DETAILS |
| --- | --- | --- | --- | --- | --- |
| 
compound-beta



 | 

Groq



 | 

131,072



 | 

8,192



 | 

\-



 | 

[Details](https://console.groq.com/docs/agentic-tooling/compound-beta)



 |
| 

compound-beta-mini



 | 

Groq



 | 

131,072



 | 

8,192



 | 

\-



 | 

[Details](https://console.groq.com/docs/agentic-tooling/compound-beta-mini)



 |

  
[

Learn More About Agentic Tooling

Discover how to build powerful applications with real-time web search and code execution





](https://console.groq.com/docs/agentic-tooling)

Deprecated models are models that are no longer supported or will no longer be supported in the future. See our deprecation guidelines and deprecated models [here](https://console.groq.com/docs/deprecations).

Hosted models are directly accessible through the GroqCloud Models API endpoint using the model IDs mentioned above. You can use the `https://api.groq.com/openai/v1/models` endpoint to return a JSON list of all active models:

```
1import requests
2import os
3
4api_key = os.environ.get("GROQ_API_KEY")
5url = "https://api.groq.com/openai/v1/models"
6
7headers = {
8    "Authorization": f"Bearer {api_key}",
9    "Content-Type": "application/json"
10}
11
12response = requests.get(url, headers=headers)
13
14print(response.json())
```

### Was this page helpful?
